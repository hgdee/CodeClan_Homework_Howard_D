---
title: "`dplyr` Weekend Homework"
output:
  html_document:
    toc: true
    toc_float: true
    df_print: paged
    css: ../../../styles.css
  pdf_document: default
---

```{r}
library(tidyverse)
```
Not worried about the conflicts - would remove this text above (tidyverse output) but still insecure about such a rash decision!

Try out a long filepath name to see how read_cvs copes



```{r}
book_ratings <- read_csv("c:/users/howard/documents/GitHub/CodeClan/d12_classnotes/week_01/day_5/2_weekend_homework/data/books.csv")
book_ratings
```

I have no knowledge of the data and so am uncertain of the difference between ratings_count data and text_reviews_count.

```{r}
dim(book_ratings)
```


```{r}
glimpse(book_ratings)
```

```{r}
book_ratings %>% summarise(across(.cols=everything(),.fns = ~ sum(is.na(.x))))
```
Wasn't expecting that but suspect there must be zeroes in there.

Tried screening for zeroes with an elegant  https://stackoverflow.com/questions/55201967/identifying-rows-with-values-equal-to-0-in-r  

```{r}
 which(colSums(book_ratings == 0) >  0)
```
Tried to confirm these counts but an immediate problem because the numbers didn't match other counts - but think they were column positions.  I don't care about num_pages as I assume if it had been rated there must be pages - therefore accidental error and can't see it being a factor. But on reflection will take it out.

```{r}
 book_ratings %>% 
    filter(average_rating == 0 | 
           ratings_count == 0 | 
           text_reviews_count == 0  |
           num_pages == 0) %>% 
   select(bookID,average_rating, ratings_count, text_reviews_count, num_pages)  
```
So now I can exclude these rows.
 
```{r}

book_ratings_cleaned <- book_ratings %>% 
           filter(!(average_rating == 0 | 
                  ratings_count    == 0 | 
                  text_reviews_count == 0  |
                  num_pages == 0))
book_ratings_cleaned
```
 
```{r}
11123 - 10439
```
This equals my excluded rows above so I'm happy. I assume this is wrangled data now so I'll try to push on to analysis.

Actually will dump some columns.

```{r}
book_ratings_wrangled <- subset(book_ratings_cleaned, select = -c(isbn,isbn13,rowid,language_code))
book_ratings_wrangled
```
The output above looks ugly because of the gaps but it is functional.

I think I should try to get some data about best sellers, authors totals, authors average rating across all books, publishers totals etc.

```{r}
book_ratings_wrangled %>% group_by(authors) %>%               
        slice_max(ratings_count, n = 1, with_ties = FALSE) %>%
        select(authors,ratings_count) %>%
        arrange(desc(ratings_count))  %>%
        head(10)
       

       
       
                 
```
The worst rated authors
```{r}
book_ratings_wrangled %>% group_by(authors) %>%               
        slice_min(ratings_count, n = 1, with_ties = FALSE) %>%
        select(authors,ratings_count) %>%
        arrange(ratings_count) %>%
        head(10)
```

```{r}
book_ratings_wrangled %>% group_by(publisher) %>%               
        slice_max(ratings_count, n = 1, with_ties = FALSE) %>%
        select (publisher,ratings_count) %>%
        arrange(desc(ratings_count))  %>%
        head(10)
```

             
```{r}

year_rating <- book_ratings_wrangled %>% 
        slice_max(ratings_count, n=10000, with_ties = FALSE) 





```
require(stats)
require(graphics)
attach(year_rating)
x <- factor(year_rating$publication_date)
y <- factor(year_rating$ratings_count)
ggplot2(x,y, main = "Publication Date") 
```{r}

```
     
     
   

x <- year_rating$publication_date
y <- year_rating$ratings_count
ggplot2(x,y, main = "Publication Date")   




I'm not sure how to proceed but referred to https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf Appendix A "A sample session" and hope the gist of that works.


